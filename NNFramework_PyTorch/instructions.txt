
Description of the main configurable parameters:
-------------------------------------------------------------------

[DEFAULT]
mode: takes values 'train' or 'test'.
model_path: path of the training output folder. Model checkpoints are saved in this folder. 
model_base_filename: the prefix to give the model checkpoint filename.
model_restore_filename: comment out if training from scratch. Otherwise set to the fullpath of the model to restore.


[NETWORK]
stain_init_name: the name of the set of reference stain vectors that is used as key to retrieve the stains in the network class.
n_stains: number of stains in the image. 

[COST]
lambda_inv: weight of the inverse regularization loss. default = 1

[TRAIN_DATA], [VALIDATE_DATA], [TEST_DATA]
filepath_data: folder path containing training images
filepath_label: set to same value as filepath_data
input_img_height: final height of image to input to model. In [TEST_DATA] we do not change the input size and set it to -1 accordingly.
input_img_width: final width of image to input to model. In [TEST_DATA] we do not change the input size and set it to -1 accordingly.
pad_y: input padding in y dimension. We do not use same convolution, so we add padding to make output height the same size as input_img_height.
pad_x: input padding in x dimension. We do not use same convolution, so we add padding to make output width the same size as input_img_width.
Rest of the parameters are for specifying augmentation, preprocessing, and postprocessing parameters.

[TRAINER]
optimizer_type: takes values 'ADAM' or 'SGD'
max_epochs: Number of training epochs
learning_rate: learning rate
batch_size: batch size
display_step: save loss every <display_step> iterations
save_best_only: takes values 'True' or 'False'. When True, saves model checkpoint only when their is improvement in loss. When False, saves model checkpoint every epoch.
validate_step: running validation and possibly save model checkpoint every <validate_step> epochs. Default = 10.

[TESTER]
out_dir: folder path to save output predictions
batch_size: batch size



Running training and test:
--------------------------------

- To change the set of reference stain vectors:
1. In NNFramework_PyTorch/sa_networks/multiplex_autoencoder_fixed_stains_arch3_next3_input_stain.py 
add the reference stain color vectors in the dictionary self.stains_dict. 
2. Set the key to the stain dictionary name set in used in config --> [NETWORK] --> stain_init_name
3. Set the number of stains config --> [NETWORK] --> n_stains
Note that the stains must contain an entry that represents the background color.

- Training data preparation:
We extracted slightly overlapping patches of 400x400 at 20x  magnification. During training these patches are scaled to 263x263 by the dataloader. 

- Test data preparation:
The test patches are extracted at 20x magnification. During inference, no scaling is performed.


- To train/test:
cd NNFramework_Pytorch_external_call
CUDA_VISIBLE_DEVICES='1' nohup  python ./external_run.py <config file path> 0  >> <output log file path>&
Example:
cd NNFramework_Pytorch_external_call
CUDA_VISIBLE_DEVICES='1' nohup  python ./external_run.py ../NNFramework_PyTorch/config_multiplex_ae1.0_train/config_multiplex-ae_rgb2stains_simple-w-mp3_nocrop_inv_aux_task_input_stain_wsi2_split1.ini 0  >> /mnt/data05/shared/sabousamra/mihc/checkpoints/rgb2stains_inv_aux_task_input_stain_wsi2_split1/log.txt&

Postprocessing:
--------------------------------
- To visualize the raw stain concentration maps:
use method visualize_raw_stain_conc_map() in src_postprocess/vis_different_thresholds.py
Set the following variables:
text_2_rgb_id: a dictionary with key = biomarker name, and value = [<alternative RGB color to use in biomarker visualization>, <channel indx>, <one-hot encoding of channel index>, <stain reference RGB color>]
root: path of root directory containing all evaluation results
conc_dir_name: folder inside <root> directory. All model predictions are in <root>/<conc_dir_name>.
im_dir: path of folder containing the test images
The method output will be in <root>/<conc_dir_name>_vis.
See example in the source file.

- To visualize the thresholded stain concentration maps at different thresholds:
use method visualize_raw_stain_conc_map_by_threshold() in src_postprocess/vis_different_thresholds.py
Set the following variables:
text_2_rgb_id: a dictionary with key = biomarker name, and value = [<alternative RGB color to use in biomarker visualization>, <channel indx>, <one-hot encoding of channel index>, <stain reference RGB color>]
root: path of root directory containing all evaluation results
conc_dir_name: folder inside <root> directory. All model predictions are in <root>/<conc_dir_name>.
im_dir: path of folder containing the test images
threshold_arr: array of threshold values to use.
The method output will be in <root>/<conc_dir_name>_thresholds_vis.
See example in the source file.
Note:
The visualizations are used to select thresholds based on validation set. The hysteresis thresholding, has 2 thresholds: high-thresh. and low-thresh. 
Select high-thresh to reflect confident regions that belong to the stain, and select low-thresh to reflect how much the regions of confidence are expanded to cover the stained area.

- To get the stain segmentation maps:
use method argmax_all_conc_thresh_mask_hysteresis() in src_postprocess/seg_argmax.py
Set the following variables:
text_2_rgb_id: a dictionary with key = biomarker name, and value = [<alternative RGB color to use in biomarker visualization>, <channel indx>, <one-hot encoding of channel index>, <stain reference RGB color>]
stain_names: the list of biomarker names excluding the background.
size_thresh_dict: a dictionary with  key = biomarker name, and value = size in pixels. predicted components with smaller size are discarded. This helps to get rid of prediction noise corresponding to noise in tissue, in the form of tiny scattered predictions.
root: path of root directory containing all evaluation results
conc_dir_name: folder inside <root> directory. All model predictions are in <root>/<conc_dir_name>.
im_dir: path of folder containing the test images
thresh_dict_high and thresh_dict_low: dictionaries of high and low thresholds needed for hysteresis thresholding.
The method output will be in <root>/<conc_dir_name>_seg.
See example in the source file.
Note that since the annotation uses dots at the approximate center of cells which can often stain free, especially in the case of tumor cells. To be able to make fair evaluation, in the postprocessing we apply a small dilation and fill the holes.

- To visualize the stain segmentation maps:
Use the methods visualize_mask_img() and visualize_all_stains_in_single_mask() in src_postprocess/vis_seg.py
The method output will be in <root>/<conc_dir_name>_seg_vis.
See example in the source file.

- To evaluate the f-score compare to a ground truth multi-class dot map use example in src_eval_metric/eval_fscore_96patches.py

- To evaluate the image reconstruction using the trained model, use the code in src_eval_metric/96patches_eval_reconstruction.py
The code evaluates the Structural Similarity (SSIM), Peak Signal-to-Noise Ratio (PSNR), Mean Squared Error (mse), Learned Perceptual Image Patch Similarity (LPIPS)









